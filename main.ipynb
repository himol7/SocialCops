{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "\n",
    "data = pd.read_csv(\"Monthly_data_cmo.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"state_name\"], axis = 1, inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation\n",
    "\n",
    "-  Removing Duplicate/Erroneous Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Commodity.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As it can be observed, there are many commodities with same names but are recorded as 2 different commodities pertaining to use of capitals.** <br/>\n",
    "As for an example: *'Paddy-Unhusked' and 'PADDY-UNHUSKED', 'Bajri' and 'BAJRI', 'Garlic' and 'GARLIC'*  <br/>\n",
    "**So, I convert all the commodity names to lowercase and merge the records of similar commodities. <br/>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all Commodity names to lowercase in order to avoid duplicate entries\n",
    "\n",
    "data[\"Commodity\"] = [x.lower() for x in data[\"Commodity\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without loss of generality, I merge the commodities which register under a single name to one particular APMC on the same date with same minimum, maximum and modal prices.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Records of all the commodities which have been registered under same names.\n",
    "\n",
    "data[data.duplicated(['APMC', 'Commodity', 'date', 'min_price', 'max_price', 'modal_price'], keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As, it can be observed, registering commodities with all capitals and with Camel case has caused duplicate/erroneous entries.** <br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.duplicated(['APMC', 'Commodity', 'date', 'min_price', 'max_price', 'modal_price'], keep=False)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**So, there are 20 such records which need to be merged** <br/>\n",
    "<br/>\n",
    "**To merge these records, I add the total arrival in quintals and assign it to a single record and delete the second one.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the list of indexes which contain duplicate entries\n",
    "\n",
    "j = np.array(data.loc[data.duplicated(['APMC', 'Commodity', 'date', 'min_price', 'max_price', 'modal_price'], keep=False)].index)\n",
    "d = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding and assigning total arrivals in quintal to one record\n",
    "\n",
    "for i in range(0, len(j)-1, 2):\n",
    "    data.loc[j[i], \"arrivals_in_qtl\"] = data.loc[j[i]][\"arrivals_in_qtl\"] + data.loc[j[i+1]][\"arrivals_in_qtl\"]\n",
    "    d.append(j[i+1])\n",
    "\n",
    "data.loc[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As it can be observed, values of alternate records starting from first one have been updated**<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Size of data before dropping extra rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(d, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Size of data after dropping extra rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Therefore, 10 duplicate/erroneous records have been dropped**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with Minimum Support Price\n",
    " - Comparing the commodities whose MS Price is available in data given with their Minimum Price, Maximum Price and Modal Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading file in which MSPs are given\n",
    "\n",
    "file = pd.read_csv(\"CMO_MSP_Mandi.csv\")\n",
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.year.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As it can be observed, 'file' contains MSPs for years 2012 to 2016, but Min, Max and Modal prices are known for year 2014 to 2016 only.** <br/>\n",
    "**So, rows having MSPs for years earlier than 2014 can be dropped**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.drop(file[file[\"year\"] < 2014].index, inplace = True)\n",
    "file.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More than 50 records dropped**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for null values in dataframe file\n",
    "    \n",
    "file.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10 records where MSP is missing** <br/>\n",
    "**So we remove these records**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file[file[\"ms_price\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10 records dropped.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.msp_filter.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSP Filter is same for all records, therefore, it can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.drop([\"msp_filter\"], axis = 1, inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, to compare the prices, I create a new dataframe which contains data only about the commodities for which all 4 prices(Min, Max, Modal, MSP) are known. <br/>\n",
    "**So, I perform an inner join on the exisitng dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all Commodity names to lowercase\n",
    "\n",
    "file[\"commodity\"] = [x.lower() for x in file[\"commodity\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file[file.duplicated(['commodity', 'year', 'Type'], keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, no duplicate records found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming column names to be consistent across both files\n",
    "\n",
    "file.columns = ['Commodity', 'Year', 'Type', 'ms_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.merge(file, data, on = ['Commodity', 'Year'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organising dataframe\n",
    "\n",
    "combined.drop([\"Month\", \"district_name\"], axis = 1, inplace =True)\n",
    "combined= combined[['Commodity', 'APMC', 'Year', 'date', 'min_price', 'modal_price', 'max_price', 'ms_price', 'arrivals_in_qtl']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations across clusters formed by Commodities and Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g =  combined.groupby([\"Commodity\", \"APMC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Minimum, Maximum, Modal and MS prices for each cluster: APMC and Commodity\n",
    "\n",
    "for k, df in g:\n",
    "    print(k)\n",
    "    df.sort_values(by = 'date', inplace = True)\n",
    "    plt.figure()\n",
    "    plt.plot( 'date', 'min_price', data=df, marker='+', color='blue', label = \"Minimum Price\")\n",
    "    plt.plot( 'date', 'max_price', data=df, marker='s', color='green', label = \"Maximum Price\")\n",
    "    plt.plot( 'date', 'modal_price', data=df, marker='o', color='yellow', label=\"Modal Price\")\n",
    "    plt.plot( 'date', 'ms_price', data=df, marker='*', color='red', label=\"Minimum Support Price\")\n",
    "    plt.title(k)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
